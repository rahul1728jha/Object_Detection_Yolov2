{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo Webcam Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,logging,traceback\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from yolo_utils import read_classes, read_anchors, generate_colors,draw_boxes,preprocess_video\n",
    "from yad2k.models.keras_yolo import yolo_head\n",
    "from yolo_algo_computation import yolo_eval\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the session and yolo models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "image_shape = (720., 1280.)  \n",
    "class_names = read_classes(\"model_data/coco_classes.txt\")\n",
    "anchors = read_anchors(\"model_data/yolo_anchors.txt\")\n",
    "yolo_model = load_model(\"model_data/yolo.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))\n",
    "scores, boxes, classes,boxes_before_nms = yolo_eval(yolo_outputs, image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to predict the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sess, image_file):\n",
    "    image_data = preprocess_video(image_file, model_image_size = (608, 608))\n",
    "    out_scores, out_boxes, out_classes,boxes_before_nms_out = sess.run([scores,boxes,classes,boxes_before_nms],\n",
    "                                                                       feed_dict={yolo_model.input:image_data,\n",
    "                                                                                  K.learning_phase(): 0})\n",
    "    return out_scores, out_boxes, out_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontScale= 1\n",
    "lineType = 2\n",
    "\n",
    "cap = cv2.VideoCapture(cv2.CAP_DSHOW + 1)\n",
    "\n",
    "#height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#cap.set(cv2.CAP_PROP_FPS,5)\n",
    "#writer = cv2.VideoWriter('webcam_output/webcam_detection.mp4',cv2.VideoWriter_fourcc(*'DIVX'),5,(width,height) )\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,1280)\n",
    "cap.set(cv2.CAP_PROP_FPS,5)\n",
    "writer = cv2.VideoWriter('webcam_output/webcam_detection.mp4',cv2.VideoWriter_fourcc(*'DIVX'),5,(1280,720) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret,frame = cap.read()\n",
    "        \n",
    "        if ret is False:\n",
    "            print('Camera might be off')\n",
    "            break\n",
    "        image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        #Operations can be done here on the video\n",
    "        if image is None:\n",
    "            print('None image')\n",
    "        else:\n",
    "            out_scores, out_boxes, out_classes = predict(sess, image)\n",
    "        colors = generate_colors(class_names)\n",
    "        \n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "\n",
    "            label = '{} {:.2f}'.format(predicted_class, score)\n",
    "            \n",
    "            top, left, bottom, right = box\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(image.shape[0], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(image.shape[1], np.floor(right + 0.5).astype('int32'))\n",
    "            \n",
    "            text_origin_text = (left, top - 10)\n",
    "            \n",
    "            cv2.rectangle(frame,(left, top),(right, bottom),colors[c],thickness=4)\n",
    "            cv2.putText(frame,label,text_origin_text,cv2.FONT_HERSHEY_SIMPLEX,fontScale,colors[c],lineType)\n",
    "        \n",
    "        writer.write(frame)\n",
    "        \n",
    "        cv2.namedWindow('frame', cv2.WND_PROP_FULLSCREEN)\n",
    "        cv2.setWindowProperty('frame', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "except Exception as e:\n",
    "    logging.error(traceback.format_exc())\n",
    "finally:\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
